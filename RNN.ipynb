{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a504bd5-33f3-4135-b694-5d160efe0736",
   "metadata": {},
   "source": [
    "# Cuda setup\n",
    "Check if cuda is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0699a32e-8d74-4417-b8c7-43e55639f628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc568980-9012-4439-b9c4-bae733988f00",
   "metadata": {},
   "source": [
    "# Import data from source\n",
    "METHOD 1: install yfinance in the environment hosting python and jupyter. I used Anaconda, and installed through conda terminal into my environment.\n",
    "\n",
    "*pip install yfinance*\n",
    "\n",
    "Use the yfinance API to retrieve company data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa97f9a-30e8-4452-b67d-583a13662bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yahoo finance api to collect stock data\n",
    "import yfinance as yf\n",
    "import os\n",
    "\n",
    "# datetime imports to work with dates\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# alpaca api to collect stock data\n",
    "from alpaca_trade_api.rest import REST, TimeFrame, TimeFrameUnit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0af98-4596-4825-ba6b-da68f5872ca6",
   "metadata": {},
   "source": [
    "# Process data from csv files\n",
    "Use pandas library for processing files\n",
    "\n",
    "Use matplotlib to display graphs and visualizations.\n",
    "\n",
    "Use torch to create and train a RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7576d49-c91e-4e00-a572-9daca579a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb/anaconda3/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/lb/anaconda3/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c5609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lb\n",
      ".motd_shown\n",
      "my_array.npy\n",
      ".bash_logout\n",
      ".sudo_as_admin_successful\n",
      "cuda-repo-wsl-ubuntu-12-9-local_12.9.1-1_amd64.deb\n",
      "DataCollector.ipynb\n",
      "Terminal_Output.txt\n",
      "image_filtering.ipynb\n",
      ".gitconfig\n",
      ".profile\n",
      "RNN.ipynb\n",
      "Style_Transfer_Exercise.ipynb\n",
      ".lesshst\n",
      ".bash_history\n",
      ".bashrc\n",
      "build_cnn.ipynb\n",
      "/mnt/c/Users/LPC/Documents/GitHub/CSCI611-NNSTOCKS\n",
      "/mnt/c/Users/LPC/Documents/GitHub/CSCI611-NNSTOCKS\n",
      "AAPL_intraday.csv\n",
      "AAPL_intraday1.csv\n",
      "AMD_intraday.csv\n",
      "AMD_intraday1.csv\n",
      "first_try.ipynb\n",
      "model_trained.pt\n",
      "README.md\n",
      "RNN.ipynb\n"
     ]
    }
   ],
   "source": [
    "#Change directory for Lorne's jupyter notebook\n",
    "# I am mixing windows and wsl on windows so I need to manaually change the directory, so you won't need to when you run it\n",
    "if True:\n",
    "    # See files in current directory\n",
    "    import os\n",
    "\n",
    "    current_directory = os.getcwd()\n",
    "    print(current_directory)\n",
    "\n",
    "    entries = os.listdir('.')\n",
    "    files = [entry for entry in entries if os.path.isfile(entry)]\n",
    "\n",
    "    for file_name in files:\n",
    "        print(file_name)\n",
    "\n",
    "    %cd \"/mnt/c/Users/LPC/Documents/GitHub/CSCI611-NNSTOCKS\"\n",
    "\n",
    "    current_directory = os.getcwd()\n",
    "    print(current_directory)\n",
    "\n",
    "    entries = os.listdir('.')\n",
    "    files = [entry for entry in entries if os.path.isfile(entry)]\n",
    "\n",
    "    # Print the names of the files\n",
    "    for file_name in files:\n",
    "        print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba0b69",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "StockDataset class to hold pytorch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f264cc-de65-4935-ac22-8300a6df8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_percentage = 6\n",
    "valid_percentage = 2\n",
    "testing_percentage = 2\n",
    "class StockDataset(torch.utils.data.Dataset[float]):\n",
    "    def __init__(self, sequences, targets):\n",
    "        super(StockDataset).__init__()\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)    \n",
    "    def __getitem__(self, index):\n",
    "        sequence = torch.tensor(self.sequences[index], dtype=torch.float32).unsqueeze(-1)#sequence at index \n",
    "        target = torch.tensor(self.targets[index], dtype=torch.float32)#test_value at index\n",
    "        return sequence, target\n",
    "        \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn1 = nn.RNN(input_size=1, hidden_size=128, num_layers=2, nonlinearity='tanh', bias=True, batch_first=True, dropout=0.0, bidirectional=False, device=None, dtype=None)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.output, self.hidden = self.rnn1(x)\n",
    "        prediction = self.fc(self.output[:, -1, :])\n",
    "        return prediction.squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7b0cd",
   "metadata": {},
   "source": [
    "# get_yahoo_stock_data(name, interval=\"5m\", period=\"7d\")\n",
    "\n",
    "unction that calls yfinance to get stock data from a defined time period\n",
    "\n",
    "@params stock_name: name of the stock to get data for\n",
    "\n",
    "@params interval: interval of the data, default is 15 minutes\n",
    "\n",
    "@params months: number of months to get data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef45ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate stock price data from yahoo finance \n",
    "def get_yahoo_stock_data(name, interval=\"5m\", period=\"7d\"):\n",
    "    data = yf.download(name, interval=interval, period=period)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674153a",
   "metadata": {},
   "source": [
    "# get_alpaca_stock_data(name, interval=\"15\", months=\"6\") \n",
    "\n",
    "function calls alpaca api to get stock data for a defined time period starting from June 1st 2021\n",
    "\n",
    "@params stock_name: name of the stock to get data for\n",
    "\n",
    "@params interval: interval of the data, default is 15 minutes\n",
    "\n",
    "@params months: number of months to get data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ed9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate stock price data from alpaca\n",
    "def get_alpaca_stock_data(name, interval=\"15\", months=\"6\"):\n",
    "    name_of_file = name + \"_intraday1.csv\"\n",
    "\n",
    "    start_date = date(2021, 6, 1)\n",
    "    end_date = start_date + relativedelta(months=int(months))  # Adds months\n",
    "\n",
    "    api = REST('PKJ41QP5QU0TYS4S1BYB', 'o5HVFGx0XWSMoMyeQdRJwG1apYXtuMNcguWpjqqe')\n",
    "\n",
    "    data = api.get_bars(name, TimeFrame(int(interval), TimeFrameUnit.Minute), start_date, end_date, adjustment='raw').df\n",
    "\n",
    "    data = data.rename(columns={\"close\": \"Close\", \"open\": \"Price\", \"high\": \"High\", \"low\": \"Low\", \"volume\": \"Volume\", \"datetime\": \"Datetime\", \"ticker\": \"Ticker\"})\n",
    "\n",
    "    data.to_csv(name_of_file)\n",
    "\n",
    "    return name_of_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e32344e",
   "metadata": {},
   "source": [
    "# plot_loss(training_loss_array, validation_loss_array, epochs)\n",
    "\n",
    "Creates a matplotlib plot of the training and validation loss\n",
    "\n",
    "@params training_loss_array: Array of training loss values\n",
    "\n",
    "@params validation_loss_array: Array of validation loss values\n",
    "\n",
    "@params epochs: Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aad5621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a matplotlib plot of the training and validation loss\n",
    "def plot_loss(training_loss_array, validation_loss_array, epochs):\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.plot(range(1, int((epochs)/10) + 1), training_loss_array, marker='o', linestyle='-', color='b', label='Training Loss')\n",
    "\n",
    "    # Plot validation loss\n",
    "    plt.plot(range(1, int((epochs)/10) + 1), validation_loss_array, marker='x', linestyle='--', color='r', label='Validation Loss')\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title('Training vs Validation Loss Over Epochs')\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    # Add grid and legend\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "\n",
    "    # Add x-axis ticks\n",
    "    plt.xticks(range(1, (int((epochs + 1)/10)+1), 1))\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb0ecf",
   "metadata": {},
   "source": [
    "# plot_target_vs_predicted_values(target_values_array, predicted_values_array, batch_size)\n",
    "\n",
    "Creates a matplotlib plot of the target values vs the predicted values.\n",
    "\n",
    "@params target_values_array: Array of actual real values of selected stock for testing phase of RNN\n",
    "\n",
    "@params predicted_values_array: Array of predicted values generated by RNN\n",
    "\n",
    "@params batch_size: Number of values in target_values_array and predicted_values_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83b593e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a matplotlib plot of the training and validation loss\n",
    "def plot_target_vs_predicted_values(target_values_array, predicted_values_array, batch_size):\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot target values\n",
    "    plt.plot(range(1, batch_size + 1), target_values_array, marker='o', linestyle='-', color='b', label='Target Values')\n",
    "\n",
    "    # Plot predicted values\n",
    "    plt.plot(range(1, batch_size + 1), predicted_values_array, marker='x', linestyle='--', color='r', label='Predicted Values')\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title('Target vs Predicted Stock Values')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Stock Value')\n",
    "\n",
    "    # Add grid and legend\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "\n",
    "    # Add x-axis ticks\n",
    "    plt.xticks(range(1, batch_size, 1))\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf73192",
   "metadata": {},
   "source": [
    "# plot_target_vs_predicted_values(target_values_array, predicted_values_array, batch_size)\n",
    "\n",
    "Creates a matplotlib plot of the target values vs the predicted values.\n",
    "\n",
    "@params target_values_array: Array of actual real values of selected stock for testing phase of RNN\n",
    "\n",
    "@params predicted_values_array: Array of predicted values generated by RNN\n",
    "\n",
    "@params batch_size: Number of values in target_values_array and predicted_values_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "848fafe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_2d(data):\n",
    "    \"\"\"\n",
    "    Standardizes a 2D array of data.\n",
    "    \n",
    "    Parameters:\n",
    "    data (numpy.ndarray): A 2D array of data to be standardized.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The standardized data.\n",
    "    \"\"\"\n",
    "    average_val = np.mean(data)\n",
    "    std_val = np.std(data)\n",
    "    standardized_data = (data - average_val) / std_val\n",
    "    return standardized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f3c7f-aee6-4d8b-961a-bb7c073dd811",
   "metadata": {},
   "source": [
    "# Display relevant information for formatting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1056a69-21ac-4d87-8daa-760ac05dfc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_initializer:\n",
    "    #\n",
    "    def __init__(self, retrieve, name, recomp, nval, ival, pval, batch_size, num_workers, epochs, learning_rate, lr_scheduler_rate, beta1, beta2):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_scheduler_rate = lr_scheduler_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        if(retrieve == True):\n",
    "            if (stock_data_source == \"yahoo\"):\n",
    "                self.csv_name = self.retrieve_csv(name, recomp, nval, str(ival[0])+ival[1], str(pval[0])+pval[1])\n",
    "            else:\n",
    "                self.csv_name = get_alpaca_stock_data(name, stock_interval, stock_period)\n",
    "        else:\n",
    "            self.csv_name = name\n",
    "        self.df=pd.read_csv(name + \"_intraday1.csv\")\n",
    "        self.show_df_info()\n",
    "        #format data, and prepare it for RNN\n",
    "        if(stock_data_source == \"yahoo\"):\n",
    "            price = self.df['Close'].to_list()[2:]\n",
    "            self.axis_labels = self.df['Price'].to_list()[2:]\n",
    "        else:\n",
    "            price = self.df['Close'].to_list()[1:]\n",
    "            self.axis_labels = self.df['Price'].to_list()[1:]\n",
    "        date_format_with_time = \"%Y-%m-%d %H:%M:%S\"\n",
    "        self.price_inputs = [float(x) for x in price]\n",
    "        self.price_inputs = standardize_2d(self.price_inputs)\n",
    "        sequence_length = 4\n",
    "        #Training sets\n",
    "        self.train_seq = []\n",
    "        self.train_tar = []\n",
    "        #Validation sets\n",
    "        self.valid_seq = []\n",
    "        self.valid_tar = []\n",
    "        #Testing sets\n",
    "        self.test_seq = []\n",
    "        self.test_tar = []\n",
    "        #choose a selected time range\n",
    "        #NOTE\n",
    "        train_range = (len(self.price_inputs)//10 * training_percentage)\n",
    "        print(len(self.price_inputs))\n",
    "        print(train_range)\n",
    "        valid_range_beg = train_range\n",
    "        valid_range_end = train_range + (len(self.price_inputs)//10 * valid_percentage)\n",
    "        print(valid_range_end)\n",
    "        test_range_beg = valid_range_end\n",
    "        test_range_end = valid_range_end + (len(self.price_inputs)//10 * testing_percentage)\n",
    "        print(test_range_end)\n",
    "        #generate sequences and targets list for loading data\n",
    "        for i in range(train_range - sequence_length):\n",
    "            seq = self.price_inputs[i:i+sequence_length]\n",
    "            self.train_seq.append(seq)\n",
    "            temp = self.price_inputs[i+sequence_length]\n",
    "            self.train_tar.append(temp)\n",
    "        for j in range(valid_range_beg, valid_range_end-sequence_length):\n",
    "            seq = self.price_inputs[j:j+sequence_length]\n",
    "            self.valid_seq.append(seq)\n",
    "            temp = self.price_inputs[j+sequence_length]\n",
    "            self.valid_tar.append(temp)\n",
    "        for k in range(test_range_beg, test_range_end-sequence_length):\n",
    "            seq = self.price_inputs[k:k+sequence_length]\n",
    "            self.test_seq.append(seq)\n",
    "            temp = self.price_inputs[k+sequence_length]\n",
    "            self.test_tar.append(temp)\n",
    "        train_data = StockDataset(self.train_seq, self.train_tar)\n",
    "        valid_data = StockDataset(self.valid_seq, self.valid_tar)\n",
    "        test_data = StockDataset(self.test_seq, self.test_tar)\n",
    "        \n",
    "        self.train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "        self.valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, num_workers=num_workers)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
    "    # retreive_csv is a file that allows the user to extract stock data from yahoo finance.\n",
    "    # @param: name, name of file\n",
    "    # @param: recomp, indicates if file needs to be recompiled\n",
    "    # @param: num, indicates which file need to be recompiled\n",
    "    def retrieve_csv(self, name, recomp, nval, ival, pval):\n",
    "        # Example: Get 1-minute intraday data for Apple (AAPL) for 1 day\n",
    "        data = get_yahoo_stock_data(stock_name, stock_interval, stock_period)\n",
    "        ext = \".csv\"\n",
    "        pt2 = \"_intraday\"\n",
    "        num = 1;\n",
    "        file_name = name + pt2 + str(num) + ext\n",
    "        found = False\n",
    "        if(recomp!=True):\n",
    "            while(found!=True):\n",
    "                if os.path.isfile(file_name):\n",
    "                    num+=1\n",
    "                    file_name = name + pt2 + str(num) + ext\n",
    "                else:\n",
    "                    found = True\n",
    "        else:\n",
    "            if(nval >= 1):\n",
    "                file_name = name + pt2 + str(nval) + ext\n",
    "            else:\n",
    "                file_name = name + pt2 + ext\n",
    "        data.to_csv(file_name)\n",
    "        return file_name\n",
    "\n",
    "    def display_fig(self):\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.title(name + \" Intraday Stock Price\")\n",
    "        plt.plot(self.axis_labels, self.price_inputs)\n",
    "        plt.xlabel(\"time\")\n",
    "        plt.ylabel(\"price\")\n",
    "        plt.xticks(self.axis_labels[::26])\n",
    "        plt.yticks(self.price_inputs[::30])\n",
    "        plt.show()\n",
    "\n",
    "    def show_df_info(self):\n",
    "        self.df.head(15)\n",
    "        self.df.tail(10)\n",
    "        print(\"Row count: \" + str(len(self.df)))\n",
    "        \n",
    "    def trainAndTest(self):\n",
    "        #RNN model\n",
    "        self.rnn1 = RNN()\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        min_loss = np.inf\n",
    "\n",
    "        if train_on_gpu:\n",
    "            self.rnn1.cuda()\n",
    "        #use MSELoss instead of MSEAbsoluteLoss (predicting next price compared to next change)\n",
    "        error = nn.MSELoss()\n",
    "        # specify optimizer\n",
    "        optimizer = torch.optim.Adam(self.rnn1.parameters(), lr=self.learning_rate, betas=(beta1, beta2))\n",
    "        #optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "        #self.price_tensor = torch.tensor(self.sequences, dtype=torch.float32).unsqueeze(-1)#input \n",
    "        #self.y_tensor = torch.tensor(self.test_vals, dtype=torch.float32)#test_values\n",
    "        # Learning rate scheduler\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=self.lr_scheduler_rate, patience=10)\n",
    "        valid_loss_min = np.inf\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "            #TRAINING\n",
    "            self.rnn1.train()\n",
    "            for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "                # move tensors to GPU if CUDA is available\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                # clear the gradients of all optimized variables\n",
    "                optimizer.zero_grad()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = self.rnn1(data)\n",
    "                # calculate the batch loss\n",
    "                loss_train = error(output, target)\n",
    "                # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss_train.backward()\n",
    "                # perform a single optimization step (parameter update)\n",
    "                optimizer.step()\n",
    "                train_loss += loss_train.item()*data.size(0)\n",
    "                if (loss_train < min_loss):\n",
    "                    min_loss = loss_train\n",
    "                    #torch.save(self.rnn1.state_dict(), \"rnn1.pth\")\n",
    "\n",
    "            scheduler.step(train_loss)  # Update learning rate\n",
    "\n",
    "    \n",
    "            ######################    \n",
    "            # validate the model #\n",
    "            ######################\n",
    "            self.rnn1.eval()\n",
    "            for batch_idx, (data, target) in enumerate(self.valid_loader):\n",
    "                # move tensors to GPU if CUDA is available\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = self.rnn1(data)\n",
    "                # calculate the batch loss\n",
    "                loss_valid = error(output, target)\n",
    "                # perform a single optimization step (parameter update)\n",
    "                valid_loss += loss_valid.item()*data.size(0)\n",
    "                if (loss_valid < min_loss):\n",
    "                    min_loss = loss_valid\n",
    "                    #torch.save(self.rnn1.state_dict(), \"rnn1.pth\")\n",
    "            # calculate average losses\n",
    "            train_loss = train_loss/len(self.train_loader.dataset)\n",
    "            valid_loss = valid_loss/len(self.valid_loader.dataset)\n",
    "            # save model if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min and (epoch+1) % 10 == 0:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "                torch.save(self.rnn1.state_dict(), 'model_trained.pt')\n",
    "                valid_loss_min = valid_loss\n",
    "\n",
    "            if (epoch+1) % 10 == 0:\n",
    "                lr = optimizer.param_groups[0][\"lr\"]\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {loss_train.item():.6f}, Validation Loss: {loss_valid.item():.6f}\")\n",
    "                training_loss_array.append(int(loss_train.item()))\n",
    "                validation_loss_array.append(int(loss_valid.item()))\n",
    "        return min_loss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "962b09fa-139f-4317-a936-9d306848fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stock variables used when collecting stock data\n",
    "#Choose which api to use to grab stock data, either \"yahoo\" or \"alpaca\"\n",
    "stock_data_source = \"alpaca\"\n",
    "\n",
    "#Loss array used to store loss values for each 10 epochs, reset each set of hyperparameters\n",
    "training_loss_array = []\n",
    "validation_loss_array = []\n",
    "test_loss = np.inf\n",
    "\n",
    "#Stock variables when using yahoo finance api\n",
    "if stock_data_source == \"yahoo\":\n",
    "    stock_name = \"AMD\"\n",
    "    stock_interval=\"5m\"\n",
    "    stock_period=\"7d\"\n",
    "    epochs = 100\n",
    "    lr_scheduler_rate = 0.8\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "\n",
    "#Stock variables when using alpaca api\n",
    "if stock_data_source == \"alpaca\":\n",
    "    stock_name = \"AMD\"\n",
    "    stock_interval=\"15\"\n",
    "    stock_period=\"12\" #months\n",
    "    epochs = 150\n",
    "    lr_scheduler_rate = 0.1\n",
    "    beta1 = 0.95\n",
    "    beta2 = 0.999\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c40c65e-3a8a-4306-bb71-a365246c813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_this_step = True\n",
    "\n",
    "if not skip_this_step:\n",
    "    #test various learning rates\n",
    "    learning_rate_list = [0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001] #revert later for hyperparameter testing, the first few values are not good current set of hyperparameters\n",
    "    #learning_rate_list = [0.0005, 0.0001, 0.00005, 0.00001]\n",
    "    best_lr = [[np.inf, np.inf] , [np.inf, np.inf]] #record two pairs of [loss, learning rate] to tune learning rate later\n",
    "    best_lr_in_loop = np.inf\n",
    "    repeated_loops_per_lr = 1\n",
    "    rnnControl = RNN_initializer(retrieve=True, name=stock_name, recomp=True, nval=1, ival=[5, \"m\"], pval=[7,\"d\"], \n",
    "                                batch_size=batch_size, num_workers=num_workers, epochs=epochs, learning_rate=0.001, lr_scheduler_rate=lr_scheduler_rate,\n",
    "                                beta1=beta1, beta2=beta2)\n",
    "    bestRNN = [rnnControl,None]\n",
    "    bestRNN_in_loop = rnnControl\n",
    "    for lr in learning_rate_list:\n",
    "        print(\"\\n\\n-------------------------------------------------------------------------------\")\n",
    "        print(\"Learning rate: \", lr, \"   Loop: \", repeated_loops_per_lr)\n",
    "        print(stock_name, \"Time interval \", stock_interval, \"min\", \"Time period: \", stock_period, 'months')\n",
    "        print(\"Batch size: \", batch_size, \"Number of workers: \", num_workers, \"Epochs: \", epochs)\n",
    "        print(\"Learning rate scheduler rate: \", lr_scheduler_rate)\n",
    "        print(\"Beta1: \", beta1, \"Beta2: \", beta2)\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        \n",
    "        for i in range(repeated_loops_per_lr):\n",
    "            rnn1 = RNN_initializer(retrieve=False, name=stock_name, recomp=True, nval=1, ival=[5, \"m\"], pval=[7,\"d\"], batch_size=batch_size, num_workers=num_workers, epochs=epochs, learning_rate=lr, lr_scheduler_rate=lr_scheduler_rate, beta1=beta1, beta2=beta2)\n",
    "            #returns\n",
    "            training_loss_array = []\n",
    "            validation_loss_array = []\n",
    "            loss = rnn1.trainAndTest()\n",
    "            if best_lr_in_loop > loss:\n",
    "                best_lr_in_loop = loss\n",
    "                bestRNN_in_loop = rnn1\n",
    "        #if found best lr, remove worst lr from list\n",
    "        if best_lr_in_loop < best_lr[0][0]:\n",
    "            best_lr[1] = best_lr[0]\n",
    "            best_lr[0] = [best_lr_in_loop, lr]\n",
    "            bestRNN[1] = bestRNN[0]\n",
    "            bestRNN[0] = bestRNN_in_loop\n",
    "            #if \n",
    "        elif best_lr_in_loop < best_lr[1][0]:\n",
    "            best_lr[1] = [best_lr_in_loop, lr]\n",
    "            bestRNN[1] = bestRNN_in_loop\n",
    "        best_lr_in_loop = np.inf\n",
    "\n",
    "        plot_loss(training_loss_array, validation_loss_array, epochs)\n",
    "\n",
    "    print(\"\\n\\nBest learning rate: \", best_lr[0][1], \"   Loss: \", best_lr[0][0])\n",
    "    print(\"Second best learning rate: \", best_lr[1][1], \"   Loss: \", best_lr[1][0])\n",
    "\n",
    "skip_this_step = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25f9432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_this_step = True\n",
    "\n",
    "if not skip_this_step:\n",
    "    learning_rate_list = []\n",
    "    difference_of_lr = best_lr[0][1] - best_lr[1][1]\n",
    "    number_of_increments = 10\n",
    "    increment = difference_of_lr / number_of_increments\n",
    "\n",
    "    for i in range(number_of_increments):\n",
    "        learning_rate_list.append(best_lr[0][1] - increment * i)\n",
    "\n",
    "    for lr in learning_rate_list:\n",
    "        print(\"\\n\\n-------------------------------------------------------------------------------\")\n",
    "        print(\"Learning rate: \", lr, \"   Loop: \", repeated_loops_per_lr)\n",
    "        print(stock_name, \"Time interval \", stock_interval, \"min\", \"Time period: \", stock_period, 'months')\n",
    "        print(\"Batch size: \", batch_size, \"Number of workers: \", num_workers, \"Epochs: \", epochs)\n",
    "        print(\"Learning rate scheduler rate: \", lr_scheduler_rate)\n",
    "        print(\"Beta1: \", beta1, \"Beta2: \", beta2)\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "        \n",
    "        \n",
    "        for i in range(repeated_loops_per_lr):\n",
    "            training_loss_array = []\n",
    "            validation_loss_array = []\n",
    "            rnn1 = RNN_initializer(retrieve=True, name=stock_name, recomp=True, nval=1, ival=[5, \"m\"], pval=[7,\"d\"], batch_size=batch_size, num_workers=num_workers, epochs=epochs, learning_rate=lr, lr_scheduler_rate=lr_scheduler_rate, beta1=beta1, beta2=beta2)\n",
    "            loss = rnn1.trainAndTest()\n",
    "            if best_lr_in_loop > loss:\n",
    "                best_lr_in_loop = loss\n",
    "\n",
    "        if best_lr_in_loop < best_lr[0][0]:\n",
    "            best_lr[1] = best_lr[0]\n",
    "            best_lr[0] = [best_lr_in_loop, lr]\n",
    "        elif best_lr_in_loop < best_lr[1][0]:\n",
    "            best_lr[1] = [best_lr_in_loop, lr]\n",
    "\n",
    "        best_lr_in_loop = np.inf\n",
    "\n",
    "\n",
    "        plot_loss(training_loss_array, validation_loss_array, epochs)\n",
    "\n",
    "\n",
    "    print(\"\\n\\nBest learning rate: \", best_lr[0][1], \"   Loss: \", best_lr[0][0])\n",
    "    print(\"Second best learning rate: \", best_lr[1][1], \"   Loss: \", best_lr[1][0])\n",
    "\n",
    "skip_this_step = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98403972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stock variables when using yahoo finance api\n",
    "if stock_data_source == \"yahoo\":\n",
    "    stock_name = \"AMD\"\n",
    "    stock_interval=\"5m\"\n",
    "    stock_period=\"7d\"\n",
    "    epochs = 100\n",
    "    lr_scheduler_rate = 0.8\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "\n",
    "#Stock variables when using alpaca api\n",
    "if stock_data_source == \"alpaca\":\n",
    "    stock_name = \"AMD\"\n",
    "    stock_interval=\"15\"\n",
    "    stock_period=\"24\" #months\n",
    "    epochs = 200\n",
    "    lr_scheduler_rate = 0.1\n",
    "    beta1 = 0.95\n",
    "    beta2 = 0.999\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a85871",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_this_step = True\n",
    "\n",
    "if not skip_this_step:\n",
    "    #test previous god perfoming rates learning rates\n",
    "    learning_rate_list = [0.00018, 0.00016, 0.00014, 0.00012]\n",
    "    best_lr = [[np.inf, np.inf] , [np.inf, np.inf]] #record two pairs of [loss, learning rate] to tune learning rate later\n",
    "    best_lr_in_loop = np.inf\n",
    "    repeated_loops_per_lr = 3\n",
    "\n",
    "    for lr in learning_rate_list:\n",
    "        print(\"\\n\\n-------------------------------------------------------------------------------\")\n",
    "        print(\"Learning rate: \", lr, \"   Loop: \", repeated_loops_per_lr)\n",
    "        print(stock_name, \"Time interval \", stock_interval, \"min\", \"Time period: \", stock_period, 'months')\n",
    "        print(\"Batch size: \", batch_size, \"Number of workers: \", num_workers, \"Epochs: \", epochs)\n",
    "        print(\"Learning rate scheduler rate: \", lr_scheduler_rate)\n",
    "        print(\"Beta1: \", beta1, \"Beta2: \", beta2)\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        \n",
    "        for i in range(repeated_loops_per_lr):\n",
    "            training_loss_array = []\n",
    "            validation_loss_array = []\n",
    "            rnn1 = RNN_initializer(retrieve=True, name=stock_name, recomp=True, nval=1, ival=[5, \"m\"], pval=[7,\"d\"], batch_size=batch_size, num_workers=num_workers, epochs=epochs, learning_rate=lr, lr_scheduler_rate=lr_scheduler_rate, beta1=beta1, beta2=beta2)\n",
    "            loss = rnn1.trainAndTest()\n",
    "            if best_lr_in_loop > loss:\n",
    "                best_lr_in_loop = loss\n",
    "\n",
    "        if best_lr_in_loop < best_lr[0][0]:\n",
    "            best_lr[1] = best_lr[0]\n",
    "            best_lr[0] = [best_lr_in_loop, lr]\n",
    "        elif best_lr_in_loop < best_lr[1][0]:\n",
    "            best_lr[1] = [best_lr_in_loop, lr]\n",
    "\n",
    "        plot_loss(training_loss_array, validation_loss_array, epochs)\n",
    "\n",
    "skip_this_step = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2285e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stock variables when using yahoo finance api\n",
    "if stock_data_source == \"yahoo\":\n",
    "    stock_name = \"AMD\"\n",
    "    stock_interval=\"5m\"\n",
    "    stock_period=\"7d\"\n",
    "    epochs = 100\n",
    "    lr_scheduler_rate = 0.8\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "\n",
    "#Stock variables when using alpaca api\n",
    "if stock_data_source == \"alpaca\":\n",
    "    stock_name = \"AMD\"\n",
    "    stock_interval=\"15\"\n",
    "    stock_period=\"12\" #months\n",
    "    epochs = 150\n",
    "    lr_scheduler_rate = 0.1\n",
    "    beta1 = 0.95\n",
    "    beta2 = 0.999\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_this_step = False\n",
    "\n",
    "if not skip_this_step:\n",
    "    #test previous god perfoming rates learning rates\n",
    "    learning_rate_list = [0.00042]\n",
    "    best_lr = [[np.inf, np.inf] , [np.inf, np.inf]] #record two pairs of [loss, learning rate] to tune learning rate later\n",
    "    best_lr_in_loop = np.inf\n",
    "    repeated_loops_per_lr = 3\n",
    "\n",
    "    for lr in learning_rate_list:\n",
    "        print(\"\\n\\n-------------------------------------------------------------------------------\")\n",
    "        print(\"Learning rate: \", lr, \"   Loop: \", repeated_loops_per_lr)\n",
    "        print(stock_name, \"Time interval \", stock_interval, \"min\", \"Time period: \", stock_period, 'months')\n",
    "        print(\"Batch size: \", batch_size, \"Number of workers: \", num_workers, \"Epochs: \", epochs)\n",
    "        print(\"Learning rate scheduler rate: \", lr_scheduler_rate)\n",
    "        print(\"Beta1: \", beta1, \"Beta2: \", beta2)\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        \n",
    "        for i in range(repeated_loops_per_lr):\n",
    "            training_loss_array = []\n",
    "            validation_loss_array = []\n",
    "            rnn1 = RNN_initializer(retrieve=True, name=stock_name, recomp=True, nval=1, ival=[5, \"m\"], pval=[7,\"d\"], batch_size=batch_size, num_workers=num_workers, epochs=epochs, learning_rate=lr, lr_scheduler_rate=lr_scheduler_rate, beta1=beta1, beta2=beta2)\n",
    "            loss = rnn1.trainAndTest()\n",
    "            if best_lr_in_loop > loss:\n",
    "                best_lr_in_loop = loss\n",
    "\n",
    "        if best_lr_in_loop < best_lr[0][0]:\n",
    "            best_lr[1] = best_lr[0]\n",
    "            best_lr[0] = [best_lr_in_loop, lr]\n",
    "        elif best_lr_in_loop < best_lr[1][0]:\n",
    "            best_lr[1] = [best_lr_in_loop, lr]\n",
    "\n",
    "        plot_loss(training_loss_array, validation_loss_array, epochs)\n",
    "\n",
    "skip_this_step = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d87229d-268e-4d1b-b0d0-4ac7c128fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output,hidden = rnn1(price_tensor)\n",
    "#print(output.shape)  # (1, 1, 128)\n",
    "#print(hidden.shape)  # (2, 1, 128)\n",
    "  # Predict 1 value from hidden_size=128\n",
    "\n",
    "#prediction = fc(output[:, -1, :])  # Take output at last time step\n",
    "#print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74fb33-cc5a-47ca-9e9c-d413adbdfaa9",
   "metadata": {},
   "source": [
    "## Test the Trained Network\n",
    "---\n",
    "Test your trained model on previously unseen data! Remember we have downloaded `train_data` and `test_data`. We will use `test_data` through `test_loader`.\n",
    "\n",
    "A \"good\" result will be a CNN that gets around 70% (or more, try your best!) accuracy on these test images.\n",
    "\n",
    "The following is working code, but you are encouraged to make your own adjustments and enhance the implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d43a4-8766-4323-bf5c-98ac8df970c4",
   "metadata": {},
   "source": [
    "### Specify [Loss Function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [Optimizer](http://pytorch.org/docs/stable/optim.html)\n",
    "---\n",
    "Decide on a loss and optimization function that is best suited for this classification task. The linked code examples from above, may be a good starting point; [this PyTorch classification example](https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py) Pay close attention to the value for **learning rate** as this value determines how your model converges to a small error.\n",
    "\n",
    "The following is working code, but you can make your own adjustments.\n",
    "\n",
    "**TODO**: try to compare with ADAM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88d78c82-f8ad-4dd7-9105-5f0b04dcc77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error = nn.MSELoss()\n",
    "#optimizer = torch.optim.Adam(prediction.parameters(), lr=0.001)\n",
    "\n",
    "#epochs = 50\n",
    "#for epoch in range(epochs):\n",
    "#    rnn1.train()\n",
    "#    fc.train()\n",
    "    \n",
    "#      output,hidden = rnn1(price_tensor)\n",
    "#    prediction = fc(output[:, -1, :])\n",
    "#    loss = error(prediction, y_tensor)\n",
    "    \n",
    "#    optimizer.zero_grad()\n",
    "#    loss.backward()\n",
    "#    optimizer.step()\n",
    "\n",
    "#    if (epoch+1) % 10 == 0:\n",
    "#        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "691e06a1-95d1-4558-8c3e-0cd8d70a765d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bestRNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d123bb314e54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbestRNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# iterate over test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestRNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bestRNN' is not defined"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "value_correct = 0\n",
    "error = nn.MSELoss()\n",
    "\n",
    "bestRNN[0].rnn1.eval()\n",
    "# iterate over test data\n",
    "for batch_idx, (data, target) in enumerate(bestRNN[0].test_loader):\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = bestRNN[0].rnn1(data)\n",
    "    # calculate the batch loss\n",
    "    loss = error(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = output.eq(target.data.view_as(output))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    value_correct += 1\n",
    "        \n",
    "# average test loss\n",
    "test_loss = test_loss/len(bestRNN[0].test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "print('Test Accuracy: %2d%% (%2d/%2d)' % (test_loss,\n",
    "    value_correct, len(bestRNN[0].test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9311fa-b706-4266-91f8-c531673109cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_array = []\n",
    "output_array = []\n",
    "for i in target:\n",
    "    target_array.append(i.item())\n",
    "for i in output:\n",
    "    output_array.append(i.item())\n",
    "\n",
    "print(\"\\n\\n-------------------------------------------------------------------------------\")\n",
    "print(\"Target Values vs Predicted Values: \")\n",
    "print(\"Stock: \", stock_name)\n",
    "print(\"Batch size: \", batch_size)\n",
    "print(\"Target Values \", target_array)\n",
    "print(\"Output Values \", output_array)\n",
    "print(\"Test Loss: \", test_loss)\n",
    "print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "plot_target_vs_predicted_values(target_array, output_array, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72dbfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_array = []\n",
    "output_array = []\n",
    "for i in target:\n",
    "    target_array.append(i.item())\n",
    "for i in output:\n",
    "    output_array.append(i.item())\n",
    "\n",
    "target_sum = 0\n",
    "for i in target_array:\n",
    "    target_sum += i\n",
    "target_average = target_sum / len(target_array)\n",
    "\n",
    "for i in range(len(target_array)):\n",
    "    target_array[i] -= target_average\n",
    "\n",
    "output_sum = 0\n",
    "for i in output_array:\n",
    "    output_sum += i\n",
    "output_average = output_sum / len(output_array)\n",
    "\n",
    "for i in range(len(output_array)):\n",
    "    output_array[i] -= output_average\n",
    "\n",
    "for i in range(len(output_array) - 1):\n",
    "    output_array[i] = output_array[i + 1]\n",
    "\n",
    "print(\"\\n\\n-------------------------------------------------------------------------------\")\n",
    "print(\"Normalized mean target values and predicted values to equal 0: \")\n",
    "print(\"Shifted predicted values 1 to the left\")\n",
    "print(\"Target differnce of begining and end stock price: $\", target_array[-1] - target_array[0])\n",
    "print(\"Predicted differnce of begining and end stock price: $\", output_array[-1] - output_array[0])\n",
    "print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "plot_target_vs_predicted_values(target_array[0:batch_size-1], output_array[0:batch_size-1], batch_size - 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "#iterate over test data\n",
    "test_data = iter(bestRNN[0].test_loader)\n",
    "data, target = next(test_data)\n",
    "if train_on_gpu:\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "#forward pass: compute predicted outputs by passing inputs to the model\n",
    "output = bestRNN[0].rnn1(data)\n",
    "print(output)\n",
    "print(target)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Target shape:\", target.shape)\n",
    "#calculate the batch loss\n",
    "loss = error(output, target)\n",
    "#update test loss\n",
    "total_loss += loss.item()\n",
    "test_loss += loss.item()/batch_size\n",
    "#calculate test accuracy for each object class\n",
    "#value_correct += 1\n",
    "\n",
    "#average test loss\n",
    "#test_loss = test_loss/len(bestRNN[0].test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "target_array = []\n",
    "output_array = []\n",
    "for i in target:\n",
    "    target_array.append(i.item())\n",
    "for i in output:\n",
    "    output_array.append(i.item())\n",
    "\n",
    "print(\"\\n\\n-------------------------------------------------------------------------------\")\n",
    "print(\"Target Values vs Predicted Values: \")\n",
    "print(\"Stock: \", stock_name)\n",
    "print(\"Batch size: \", batch_size)\n",
    "print(\"Target Values \", target_array)\n",
    "print(\"Output Values \", output_array)\n",
    "print(\"Test Loss: \", test_loss)\n",
    "print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "plot_target_vs_predicted_values(target_array, output_array, batch_size)\n",
    "\n",
    "target_array = []\n",
    "output_array = []\n",
    "for i in target:\n",
    "    target_array.append(i.item())\n",
    "for i in output:\n",
    "    output_array.append(i.item())\n",
    "\n",
    "target_sum = 0\n",
    "for i in target_array:\n",
    "    target_sum += i\n",
    "target_average = target_sum / len(target_array)\n",
    "\n",
    "for i in range(len(target_array)):\n",
    "    target_array[i] -= target_average\n",
    "\n",
    "output_sum = 0\n",
    "for i in output_array:\n",
    "    output_sum += i\n",
    "output_average = output_sum / len(output_array)\n",
    "\n",
    "for i in range(len(output_array)):\n",
    "    output_array[i] -= output_average\n",
    "\n",
    "for i in range(len(output_array) - 1):\n",
    "    output_array[i] = output_array[i + 1]\n",
    "\n",
    "print(\"\\n\\n-------------------------------------------------------------------------------\")\n",
    "print(\"Normalized mean target values and predicted values to equal 0: \")\n",
    "print(\"Shifted predicted values 1 to the left\")\n",
    "print(\"Target differnce of begining and end stock price: $\", target_array[-1] - target_array[0])\n",
    "print(\"Predicted differnce of begining and end stock price: $\", output_array[-1] - output_array[0])\n",
    "print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "plot_target_vs_predicted_values(target_array[0:batch_size-1], output_array[0:batch_size-1], batch_size - 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
