{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a504bd5-33f3-4135-b694-5d160efe0736",
   "metadata": {},
   "source": [
    "# Cuda setup\n",
    "Check if cuda is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0699a32e-8d74-4417-b8c7-43e55639f628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc568980-9012-4439-b9c4-bae733988f00",
   "metadata": {},
   "source": [
    "# Import data from source\n",
    "METHOD 1: install yfinance in the environment hosting python and jupyter. I used Anaconda, and installed through conda terminal into my environment.\n",
    "\n",
    "*pip install yfinance*\n",
    "\n",
    "Use the yfinance API to retrieve company data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfa97f9a-30e8-4452-b67d-583a13662bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yahoo finance api to collect stock data\n",
    "import yfinance as yf\n",
    "import os\n",
    "\n",
    "# datetime imports to work with dates\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# alpaca api to collect stock data\n",
    "from alpaca_trade_api.rest import REST, TimeFrame, TimeFrameUnit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0af98-4596-4825-ba6b-da68f5872ca6",
   "metadata": {},
   "source": [
    "# Process data from csv files\n",
    "Use pandas library for processing files, and use matplotlib to display graphs and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7576d49-c91e-4e00-a572-9daca579a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c5609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/LPC/Documents/GitHub/CSCI611-NNSTOCKS\n",
      "AAPL_intraday.csv\n",
      "AAPL_intraday1.csv\n",
      "AMD_intraday.csv\n",
      "AMD_intraday1.csv\n",
      "first_try.ipynb\n",
      "README.md\n",
      "RNN.ipynb\n",
      "/mnt/c/Users/LPC/Documents/GitHub/CSCI611-NNSTOCKS\n",
      "/mnt/c/Users/LPC/Documents/GitHub/CSCI611-NNSTOCKS\n",
      "AAPL_intraday.csv\n",
      "AAPL_intraday1.csv\n",
      "AMD_intraday.csv\n",
      "AMD_intraday1.csv\n",
      "first_try.ipynb\n",
      "README.md\n",
      "RNN.ipynb\n"
     ]
    }
   ],
   "source": [
    "#Change directory for Lorne's jupyter notebook\n",
    "# I am mixing windows and wsl on windows so I need to manaually change the directory, so you won't need to when you run it\n",
    "if True:\n",
    "    # See files in current directory\n",
    "    import os\n",
    "\n",
    "    current_directory = os.getcwd()\n",
    "    print(current_directory)\n",
    "\n",
    "    entries = os.listdir('.')\n",
    "    files = [entry for entry in entries if os.path.isfile(entry)]\n",
    "\n",
    "    for file_name in files:\n",
    "        print(file_name)\n",
    "\n",
    "    %cd \"/mnt/c/Users/LPC/Documents/GitHub/CSCI611-NNSTOCKS\"\n",
    "\n",
    "    current_directory = os.getcwd()\n",
    "    print(current_directory)\n",
    "\n",
    "    entries = os.listdir('.')\n",
    "    files = [entry for entry in entries if os.path.isfile(entry)]\n",
    "\n",
    "    # Print the names of the files\n",
    "    for file_name in files:\n",
    "        print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52f264cc-de65-4935-ac22-8300a6df8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(torch.utils.data.Dataset[float]):\n",
    "    def __init__(self, sequences, targets):\n",
    "        super(StockDataset).__init__()\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)    \n",
    "    def __getitem__(self, index):\n",
    "        sequence = torch.tensor(self.sequences[index], dtype=torch.float32).unsqueeze(-1)#sequence at index \n",
    "        target = torch.tensor(self.targets[index], dtype=torch.float32)#test_value at index\n",
    "        return sequence, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef45ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate stock price data from yahoo finance \n",
    "def get_yahoo_stock_data(name, interval=\"5m\", period=\"7d\"):\n",
    "    data = yf.download(name, interval=interval, period=period)\n",
    "    return data\n",
    "\n",
    "def get_alpaca_stock_data(name, interval=\"15\", months=\"6\"):\n",
    "    name_of_file = name + \"_intraday1.csv\"\n",
    "\n",
    "    start_date = date(2021, 6, 1)\n",
    "    end_date = start_date + relativedelta(months=int(months))  # Adds months\n",
    "\n",
    "    api = REST('PKJ41QP5QU0TYS4S1BYB', 'o5HVFGx0XWSMoMyeQdRJwG1apYXtuMNcguWpjqqe')\n",
    "\n",
    "    data = api.get_bars(name, TimeFrame(int(interval), TimeFrameUnit.Minute), start_date, end_date, adjustment='raw').df\n",
    "\n",
    "    data = data.rename(columns={\"close\": \"Close\", \"open\": \"Price\", \"high\": \"High\", \"low\": \"Low\", \"volume\": \"Volume\", \"datetime\": \"Datetime\", \"ticker\": \"Ticker\"})\n",
    "\n",
    "    data.to_csv(name_of_file)\n",
    "\n",
    "    return name_of_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f3c7f-aee6-4d8b-961a-bb7c073dd811",
   "metadata": {},
   "source": [
    "# Display relevant information for formatting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1056a69-21ac-4d87-8daa-760ac05dfc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_initializer:\n",
    "    #\n",
    "    def __init__(self, retrieve, name, recomp, nval, ival, pval, batch_size, num_workers, epochs, learning_rate, lr_scheduler_rate, beta1, beta2):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_scheduler_rate = lr_scheduler_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        if(retrieve == True):\n",
    "            if (stock_data_source == \"yahoo\"):\n",
    "                self.csv_name = self.retrieve_csv(name, recomp, nval, str(ival[0])+ival[1], str(pval[0])+pval[1])\n",
    "            else:\n",
    "                self.csv_name = get_alpaca_stock_data(name, stock_interval, stock_period)\n",
    "        else:\n",
    "            self.csv_name = name\n",
    "        self.df=pd.read_csv(name + \"_intraday1.csv\")\n",
    "        #format data, and prepare it for RNN\n",
    "        if(stock_data_source == \"yahoo\"):\n",
    "            price = self.df['Close'].to_list()[2:]\n",
    "        else:\n",
    "            price = self.df['Close'].to_list()[2:]\n",
    "        self.axis_labels = self.df['Price'].to_list()[2:]\n",
    "        date_format_with_time = \"%Y-%m-%d %H:%M:%S\"\n",
    "        self.price_inputs = [float(x) for x in price]\n",
    "        sequence_length = 6\n",
    "        #Training sets\n",
    "        self.train_seq = []\n",
    "        self.train_tar = []\n",
    "        #Validation sets\n",
    "        self.valid_seq = []\n",
    "        self.valid_tar = []\n",
    "        #Testing sets\n",
    "        self.test_seq = []\n",
    "        self.test_tar = []\n",
    "        #choose a selected time range\n",
    "        train_range = len(self.price_inputs)//pval[0] * (pval[0]-1)\n",
    "        test_range_beg = train_range\n",
    "        test_range_end = train_range + len(self.price_inputs)//pval[0]\n",
    "        #generate sequences and targets list for loading data\n",
    "        for i in range(train_range - sequence_length):\n",
    "            seq = self.price_inputs[i:i+sequence_length]\n",
    "            self.train_seq.append(seq)\n",
    "            temp = self.price_inputs[i+sequence_length]\n",
    "            self.train_tar.append(temp)\n",
    "        for j in range(test_range_beg, test_range_end-sequence_length):\n",
    "            seq = self.price_inputs[j:j+sequence_length]\n",
    "            self.test_seq.append(seq)\n",
    "            temp = self.price_inputs[j+sequence_length]\n",
    "            self.test_tar.append(temp)\n",
    "        train_data = StockDataset(self.train_seq, self.train_tar)\n",
    "        test_data = StockDataset(self.test_seq, self.test_tar)\n",
    "        \n",
    "        self.train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "        #valid_loader = torch.utils.data.DataLoader(self.test_vals, batch_size=batch_size, \n",
    "        #sampler=valid_sampler, num_workers=num_workers)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "    # retreive_csv is a file that allows the user to extract stock data from yahoo finance.\n",
    "    # @param: name, name of file\n",
    "    # @param: recomp, indicates if file needs to be recompiled\n",
    "    # @param: num, indicates which file need to be recompiled\n",
    "    def retrieve_csv(self, name, recomp, nval, ival, pval):\n",
    "        # Example: Get 1-minute intraday data for Apple (AAPL) for 1 day\n",
    "        data = get_yahoo_stock_data(stock_name, stock_interval, stock_period)\n",
    "        ext = \".csv\"\n",
    "        pt2 = \"_intraday\"\n",
    "        num = 1;\n",
    "        file_name = name + pt2 + str(num) + ext\n",
    "        found = False\n",
    "        if(recomp!=True):\n",
    "            while(found!=True):\n",
    "                if os.path.isfile(file_name):\n",
    "                    num+=1\n",
    "                    file_name = name + pt2 + str(num) + ext\n",
    "                else:\n",
    "                    found = True\n",
    "        else:\n",
    "            if(nval >= 1):\n",
    "                file_name = name + pt2 + str(nval) + ext\n",
    "            else:\n",
    "                file_name = name + pt2 + ext\n",
    "        data.to_csv(file_name)\n",
    "        return file_name\n",
    "\n",
    "    def display_fig(self):\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.title(name + \" Intraday Stock Price\")\n",
    "        plt.plot(self.axis_labels, self.price_inputs)\n",
    "        plt.xlabel(\"time\")\n",
    "        plt.ylabel(\"price\")\n",
    "        plt.xticks(self.axis_labels[::26])\n",
    "        plt.yticks(self.price_inputs[::30])\n",
    "        plt.show()\n",
    "\n",
    "    def show_df_info(self):\n",
    "        self.df.head(15)\n",
    "        self.df.tail(10)\n",
    "        print(\"Row count: \" + len(self.price_inputs))\n",
    "        print(\"Selected range: \" + selected_range)\n",
    "        \n",
    "    def trainAndTest(self):\n",
    "        #RNN model\n",
    "        self.rnn1 = RNN()\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        min_loss = np.inf\n",
    "\n",
    "        if train_on_gpu:\n",
    "            self.rnn1.cuda()\n",
    "        #use MSELoss instead of MSEAbsoluteLoss (predicting next price compared to next change)\n",
    "        error = nn.MSELoss()\n",
    "        # specify optimizer\n",
    "        optimizer = torch.optim.Adam(self.rnn1.parameters(), lr=self.learning_rate, betas=(beta1, beta2))\n",
    "        #optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "        #self.price_tensor = torch.tensor(self.sequences, dtype=torch.float32).unsqueeze(-1)#input \n",
    "        #self.y_tensor = torch.tensor(self.test_vals, dtype=torch.float32)#test_values\n",
    "        # Learning rate scheduler\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=self.lr_scheduler_rate, patience=10)\n",
    "        valid_loss_min = np.inf\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "            #TRAINING\n",
    "            self.rnn1.train()\n",
    "            for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "                # move tensors to GPU if CUDA is available\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                # clear the gradients of all optimized variables\n",
    "                optimizer.zero_grad()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = self.rnn1(data)\n",
    "                # calculate the batch loss\n",
    "                loss_train = error(output, target)\n",
    "                # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss_train.backward()\n",
    "                # perform a single optimization step (parameter update)\n",
    "                optimizer.step()\n",
    "                train_loss += loss_train.item()*data.size(0)\n",
    "                if (loss_train < min_loss):\n",
    "                    min_loss = loss_train\n",
    "                    #torch.save(self.rnn1.state_dict(), \"rnn1.pth\")\n",
    "\n",
    "            scheduler.step(train_loss)  # Update learning rate\n",
    "\n",
    "            self.rnn1.eval()\n",
    "            for batch_idx, (data, target) in enumerate(self.test_loader):\n",
    "                # move tensors to GPU if CUDA is available\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = self.rnn1(data)\n",
    "                # calculate the batch loss\n",
    "                loss_valid = error(output, target)\n",
    "                # perform a single optimization step (parameter update)\n",
    "                valid_loss += loss_valid.item()*data.size(0)\n",
    "                if (loss_valid < min_loss):\n",
    "                    min_loss = loss_valid\n",
    "                    #torch.save(self.rnn1.state_dict(), \"rnn1.pth\")\n",
    "        \n",
    "            if (epoch+1) % 10 == 0:\n",
    "                lr = optimizer.param_groups[0][\"lr\"]\n",
    "                print(f\"Training: Epoch {epoch+1}/{epochs}, Loss: {loss_train.item():.6f}\")\n",
    "                print(f\"Validation: Epoch {epoch+1}/{epochs}, Loss: {loss_valid.item():.6f}\")\n",
    "\n",
    "        return min_loss\n",
    "        \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn1 = nn.RNN(input_size=1, hidden_size=128, num_layers=2, nonlinearity='tanh', bias=True, batch_first=True, dropout=0.0, bidirectional=False, device=None, dtype=None)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.output, self.hidden = self.rnn1(x)\n",
    "        prediction = self.fc(self.output[:, -1, :])\n",
    "        return prediction\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "962b09fa-139f-4317-a936-9d306848fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stock variables used when collecting stock data\n",
    "stock_data_source = \"alpaca\"\n",
    "\n",
    "if stock_data_source == \"yahoo\":\n",
    "    #Stock variables when using yahoo finance api\n",
    "    stock_name = \"AMD\"\n",
    "    stock_interval=\"5m\"\n",
    "    stock_period=\"7d\"\n",
    "    epochs = 100\n",
    "    lr_scheduler_rate = 0.8\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "\n",
    "#Stock variables when using alpaca api\n",
    "if stock_data_source == \"alpaca\":\n",
    "    stock_name = \"AMD\"\n",
    "    stock_interval=\"15\"\n",
    "    stock_period=\"4\" #months\n",
    "    epochs = 100\n",
    "    lr_scheduler_rate = 0.5\n",
    "    beta1 = 0.95\n",
    "    beta2 = 0.999\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c40c65e-3a8a-4306-bb71-a365246c813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Learning rate:  0.005    Loop:  1\n",
      "AMD Time interval  15 Time period:  4\n",
      "Batch size:  16 Number of workers:  0 Epochs:  100\n",
      "Learning rate scheduler rate:  0.5\n",
      "Beta1:  0.95 Beta2:  0.999\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch 10/100, Loss: 9.030393\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loss_valid' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-80f0e43dacd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeated_loops_per_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mrnn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecomp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mival\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"m\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"d\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_scheduler_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainAndTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbest_lr_in_loop\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mbest_lr_in_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-d88d500f3f73>\u001b[0m in \u001b[0;36mtrainAndTest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training: Epoch {epoch+1}/{epochs}, Loss: {loss_train.item():.6f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation: Epoch {epoch+1}/{epochs}, Loss: {loss_valid.item():.6f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'loss_valid' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#test various learning rates\n",
    "learning_rate_list = [0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]\n",
    "best_lr = [[np.inf, np.inf] , [np.inf, np.inf]] #record two pairs of [loss, learning rate] to tune learning rate later\n",
    "best_lr_in_loop = np.inf\n",
    "repeated_loops_per_lr = 1\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    print(\"\\n\\n-------------------------------------------------------------------------------\")\n",
    "    print(\"Learning rate: \", lr, \"   Loop: \", repeated_loops_per_lr)\n",
    "    print(stock_name, \"Time interval \", stock_interval, \"Time period: \", stock_period)\n",
    "    print(\"Batch size: \", batch_size, \"Number of workers: \", num_workers, \"Epochs: \", epochs)\n",
    "    print(\"Learning rate scheduler rate: \", lr_scheduler_rate)\n",
    "    print(\"Beta1: \", beta1, \"Beta2: \", beta2)\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    \n",
    "    for i in range(repeated_loops_per_lr):\n",
    "        rnn1 = RNN_initializer(retrieve=True, name=stock_name, recomp=True, nval=1, ival=[5, \"m\"], pval=[7,\"d\"], batch_size=batch_size, num_workers=num_workers, epochs=epochs, learning_rate=lr, lr_scheduler_rate=lr_scheduler_rate, beta1=beta1, beta2=beta2)\n",
    "        loss = rnn1.trainAndTest()\n",
    "        if best_lr_in_loop > loss:\n",
    "            best_lr_in_loop = loss\n",
    "\n",
    "    if best_lr_in_loop < best_lr[0][0]:\n",
    "        best_lr[1] = best_lr[0]\n",
    "        best_lr[0] = [best_lr_in_loop, lr]\n",
    "    elif best_lr_in_loop < best_lr[1][0]:\n",
    "        best_lr[1] = [best_lr_in_loop, lr]\n",
    "\n",
    "    best_lr_in_loop = np.inf\n",
    "\n",
    "print(\"\\n\\nBest learning rate: \", best_lr[0][1], \"   Loss: \", best_lr[0][0])\n",
    "print(\"Second best learning rate: \", best_lr[1][1], \"   Loss: \", best_lr[1][0])\n",
    "\n",
    "\n",
    "learning_rate_list = []\n",
    "difference_of_lr = best_lr[0][1] - best_lr[1][1]\n",
    "number_of_increments = 10\n",
    "increment = difference_of_lr / number_of_increments\n",
    "\n",
    "for i in range(number_of_increments):\n",
    "    learning_rate_list.append(best_lr[0][1] - increment * i)\n",
    "\n",
    "for lr in learning_rate_list:\n",
    "    print(\"\\n\\n-------------------------------------------------------------------------------\")\n",
    "    print(\"Learning rate: \", lr, \"   Loop: \", repeated_loops_per_lr)\n",
    "    print(stock_name, \"Time interval \", stock_interval, \"Time period: \", stock_period)\n",
    "    print(\"Batch size: \", batch_size, \"Number of workers: \", num_workers, \"Epochs: \", epochs)\n",
    "    print(\"Learning rate scheduler rate: \", lr_scheduler_rate)\n",
    "    print(\"Beta1: \", beta1, \"Beta2: \", beta2)\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    \n",
    "    for i in range(repeated_loops_per_lr):\n",
    "        rnn1 = RNN_initializer(retrieve=True, name=stock_name, recomp=True, nval=1, ival=[5, \"m\"], pval=[7,\"d\"], batch_size=batch_size, num_workers=num_workers, epochs=epochs, learning_rate=lr, lr_scheduler_rate=lr_scheduler_rate, beta1=beta1, beta2=beta2)\n",
    "        loss = rnn1.trainAndTest()\n",
    "        if best_lr_in_loop > loss:\n",
    "            best_lr_in_loop = loss\n",
    "\n",
    "    if best_lr_in_loop < best_lr[0][0]:\n",
    "        best_lr[1] = best_lr[0]\n",
    "        best_lr[0] = [best_lr_in_loop, lr]\n",
    "    elif best_lr_in_loop < best_lr[1][0]:\n",
    "        best_lr[1] = [best_lr_in_loop, lr]\n",
    "\n",
    "    best_lr_in_loop = np.inf\n",
    "\n",
    "\n",
    "    #Make testing only, no training\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d87229d-268e-4d1b-b0d0-4ac7c128fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output,hidden = rnn1(price_tensor)\n",
    "#print(output.shape)  # (1, 1, 128)\n",
    "#print(hidden.shape)  # (2, 1, 128)\n",
    "  # Predict 1 value from hidden_size=128\n",
    "\n",
    "#prediction = fc(output[:, -1, :])  # Take output at last time step\n",
    "#print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74fb33-cc5a-47ca-9e9c-d413adbdfaa9",
   "metadata": {},
   "source": [
    "## Test the Trained Network\n",
    "---\n",
    "Test your trained model on previously unseen data! Remember we have downloaded `train_data` and `test_data`. We will use `test_data` through `test_loader`.\n",
    "\n",
    "A \"good\" result will be a CNN that gets around 70% (or more, try your best!) accuracy on these test images.\n",
    "\n",
    "The following is working code, but you are encouraged to make your own adjustments and enhance the implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d43a4-8766-4323-bf5c-98ac8df970c4",
   "metadata": {},
   "source": [
    "### Specify [Loss Function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [Optimizer](http://pytorch.org/docs/stable/optim.html)\n",
    "---\n",
    "Decide on a loss and optimization function that is best suited for this classification task. The linked code examples from above, may be a good starting point; [this PyTorch classification example](https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py) Pay close attention to the value for **learning rate** as this value determines how your model converges to a small error.\n",
    "\n",
    "The following is working code, but you can make your own adjustments.\n",
    "\n",
    "**TODO**: try to compare with ADAM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d78c82-f8ad-4dd7-9105-5f0b04dcc77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error = nn.MSELoss()\n",
    "#optimizer = torch.optim.Adam(prediction.parameters(), lr=0.001)\n",
    "\n",
    "#epochs = 50\n",
    "#for epoch in range(epochs):\n",
    "#    rnn1.train()\n",
    "#    fc.train()\n",
    "    \n",
    "#      output,hidden = rnn1(price_tensor)\n",
    "#    prediction = fc(output[:, -1, :])\n",
    "#    loss = error(prediction, y_tensor)\n",
    "    \n",
    "#    optimizer.zero_grad()\n",
    "#    loss.backward()\n",
    "#    optimizer.step()\n",
    "\n",
    "#    if (epoch+1) % 10 == 0:\n",
    "#        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e06a1-95d1-4558-8c3e-0cd8d70a765d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RNN_initializer' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c6264930ea1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m optimizer = torch.optim.Adam(list(rnn1.parameters()) + list(fc.parameters()), \n\u001b[0m\u001b[1;32m      8\u001b[0m                             lr=0.001, weight_decay=0.001)  # L2 regularization\n\u001b[1;32m      9\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RNN_initializer' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "# Define your models first\n",
    "#rnn1 = ...  # Your RNN model definition\n",
    "#fc = ...    # Your fully connected layer definition\n",
    "\n",
    "# Define loss and optimizer\n",
    "error = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(list(rnn1.parameters()) + list(fc.parameters()), \n",
    "                            lr=0.001, weight_decay=0.001)  # L2 regularization\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Add gradient clipping value\n",
    "clip_value = 1.0\n",
    "\n",
    "# Add validation set monitoring\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "no_improvement = 0\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    rnn1.train()\n",
    "    fc.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    output, hidden = rnn1(price_tensor)\n",
    "    prediction = fc(output[:, -1, :])\n",
    "    loss = error(prediction, y_tensor)\n",
    "    \n",
    "    # Backward pass with gradient clipping\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(list(rnn1.parameters()) + list(fc.parameters()), clip_value)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    # Early stopping check\n",
    "    if loss.item() < best_val_loss:\n",
    "        best_val_loss = loss.item()\n",
    "        no_improvement = 0\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9311fa-b706-4266-91f8-c531673109cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
